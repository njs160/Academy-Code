///////////////////////////////////////////R///////////////////////////////////////

//////////////////////////////////////ORI/OFFICER INJURY MERGE (2013-2018)///////////////////////////////////////

# enrich_academy_data_loop.R

# Load libraries
library(haven)       # for read_dta()
library(readr)       # for read_csv(), write_csv()
library(dplyr)
library(stringr)
library(fuzzyjoin)
library(stringdist)

# 1. Read and prepare roimatch1 and manual academy lookup
roimatch1 <- read_csv(
  "~/Downloads/roimatch1.csv",
  show_col_types = FALSE
) %>%
  rename(state_orig = statecode) %>%
  mutate(
    clean_academy = str_to_lower(academyname)
  )

# 1a. Manual city mappings for known exceptions
academy_lookup <- c(
  "university of alaska fairbanks community and technical" = "FAIRBANKS NORTH STAR BOROUGH",
  "alaska of public safety" = "SITKA",
  # ... (other mappings) ...
  "lubbock police department" = "LUBBOCK"
)

# 2. Clean roimatch1 academy names
roimatch1_clean <- roimatch1 %>%
  mutate(
    matched_city = academy_lookup[clean_academy],
    clean_academy = academyname %>%
      str_to_lower() %>%
      str_replace_all("\\b(police|training|academy|department|college|state|county|regional)\\b", " ") %>%
      str_replace_all("[^a-z]", " ") %>%
      str_squish()
  )

# 3. Define variables to select and rename
vars_to_select <- c(
  # ORI, identifiers
  "V3", "V9", "V10", "V11", "V12", "V15", "V18",
  # Injury by weapon groups
  paste0("V", c(74, 257, 440, 623, 806, 989, 1172, 1355, 1538, 1721, 1904, 2087)),
  paste0("V", c(75, 258, 441, 624, 807, 990, 1173, 1356, 1539, 1722, 1905, 2088)),
  paste0("V", c(76, 259, 442, 625, 808, 991, 1174, 1357, 1540, 1723, 1906, 2089)),
  paste0("V", c(77, 260, 443, 626, 809, 992, 1175, 1358, 1541, 1724, 1907, 2090)),
  # Non-injury by weapon groups
  paste0("V", c(79, 262, 445, 628, 811, 994, 1177, 1360, 1543, 1726, 1909, 2092)),
  paste0("V", c(80, 263, 446, 629, 812, 995, 1178, 1361, 1544, 1727, 1910, 2093)),
  paste0("V", c(81, 264, 447, 630, 813, 996, 1179, 1362, 1545, 1728, 1911, 2094)),
  paste0("V", c(82, 265, 448, 631, 814, 997, 1180, 1363, 1546, 1729, 1912, 2095)),
  # Killings
  paste0("V", c(72, 150, 333, 516, 699, 882, 1065, 1248, 1431, 1614, 1797, 1980)),
  paste0("V", c(73, 151, 334, 517, 700, 883, 1066, 1249, 1432, 1615, 1798, 1981))
)

# 4. Loop through years 2013 to 2018
for (yr in 2013:2018) {
  message("\nProcessing police_", yr, ".dta ...")

  # 4a. Read LEOK data for the year
  LEOK_data <- read_dta(sprintf("~/Downloads/police_%d.dta", yr)) %>%
    select(all_of(vars_to_select)) %>%
    rename(
      ori       = V3,
      city      = V10,
      state_nom = V11
    ) %>%
    mutate(
      statecode = toupper(substr(ori, 1, 2))
    )
  
  # 4b. Clean LEOK city names
  LEOK_clean <- LEOK_data %>%
    mutate(
      clean_city = city %>%
        str_to_lower() %>%
        str_replace_all("\\b(city|county)\\b", " ") %>%
        str_replace_all("[^a-z]", " ") %>%
        str_squish()
    )

  # 4c. Compute LEOK injury and killing totals
  LEOK_data <- LEOK_data %>%
    mutate(
      total_inj_firearms     = rowSums(across(paste0("V", c(74,257,440,623,806,989,1172,1355,1538,1721,1904,2087))), na.rm = TRUE),
      total_inj_knife        = rowSums(across(paste0("V", c(75,258,441,624,807,990,1173,1356,1539,1722,1905,2088))), na.rm = TRUE),
      total_inj_other        = rowSums(across(paste0("V", c(76,259,442,625,808,991,1174,1357,1540,1723,1906,2089))), na.rm = TRUE),
      total_inj_hands        = rowSums(across(paste0("V", c(77,260,443,626,809,992,1175,1358,1541,1724,1907,2090))), na.rm = TRUE),
      total_noninj_firearms  = rowSums(across(paste0("V", c(79,262,445,628,811,994,1177,1360,1543,1726,1909,2092))), na.rm = TRUE),
      total_noninj_knife     = rowSums(across(paste0("V", c(80,263,446,629,812,995,1178,1361,1544,1727,1910,2093))), na.rm = TRUE),
      total_noninj_other     = rowSums(across(paste0("V", c(81,264,447,630,813,996,1179,1362,1545,1728,1911,2094))), na.rm = TRUE),
      total_noninj_hands     = rowSums(across(paste0("V", c(82,265,448,631,814,997,1180,1363,1546,1729,1912,2095))), na.rm = TRUE),
      total_killed_felonious = rowSums(across(paste0("V", c(72,150,333,516,699,882,1065,1248,1431,1614,1797,1980))), na.rm = TRUE),
      total_killed_accidental= rowSums(across(paste0("V", c(73,151,334,517,700,883,1066,1249,1432,1615,1798,1981))), na.rm = TRUE)
    )

  # 4d. Fuzzy join roimatch1_clean and LEOK_clean, filter by state
  merged_raw <- stringdist_left_join(
    roimatch1_clean, LEOK_clean,
    by           = c("clean_academy" = "clean_city"),
    method       = "jw",
    max_dist     = 0.25,
    distance_col = "dist"
  ) %>%
    filter(toupper(state_orig) == statecode)

  # 4e. Select best matches
  matches_map <- merged_raw %>%
    group_by(academyname) %>%
    slice_min(dist, with_ties = FALSE) %>%
    ungroup() %>%
    transmute(academyname, matched_city = city)

  # 4f. Enrich and export
  enriched <- roimatch1_clean %>%
    left_join(matches_map, by = "academyname", suffix = c("", ".fuzzy")) %>%
    mutate(
      matched_city = coalesce(matched_city, matched_city.fuzzy)
    ) %>%
    select(-matched_city.fuzzy) %>%
    left_join(
      LEOK_data %>%
        select(
          ori, city, statecode,
          starts_with("total_inj_"), starts_with("total_noninj_"), starts_with("total_killed_")
        ),
      by = c("matched_city" = "city", "state_orig" = "statecode"),
      relationship = "many-to-many"
    ) %>%
    distinct(academyname, .keep_all = TRUE)

  # Write out CSV for this year
  write_csv(enriched, sprintf("~/Downloads/roimatch1_enriched(final%d).csv", yr))
}


//////////////////////////////////////CLEARANCE MERGE ///////////////////////////////////////
# //////////////////////////////////////ORI/CLEARANCE MERGE///////////////////////////////////////

# enrich_clearance_data.R

# Load libraries
library(haven)       # for read_dta()
library(readr)       # for read_csv()
library(dplyr)
library(stringr)
library(fuzzyjoin)
library(writexl)

# 1. Load and prepare academy ORI list
academy_data <- read_csv("~/Downloads/roimatch2.csv", show_col_types = FALSE) %>%
  rename(ORI = ori) %>%
  mutate(
    ORI = toupper(str_trim(ORI)),
    row_id = row_number()
  )

# 2. Define year range and file paths
years <- 2013:2018
file_paths <- paste0("~/Downloads/clearance_", years, ".dta")

# 3. Initialize results list for Excel export
clearance_matches <- list()

# 4. Loop through each clearance year
for (i in seq_along(years)) {
  year <- years[i]
  file <- file_paths[i]
  
  # 4a. Load clearance data
  clearance_raw <- read_dta(file)

  # 4b. Extract labels to find ACTUAL and CLEARED columns
  var_labels <- sapply(clearance_raw, function(x) attr(x, "label"), USE.NAMES = TRUE)
  fields_with_all <- var_labels[grepl("ALL FIELDS", var_labels, ignore.case = TRUE)]

  actual_vars    <- names(fields_with_all)[grepl("ACT # ALL FIELDS", fields_with_all, ignore.case = TRUE)]
  cleared_vars   <- names(fields_with_all)[grepl("TOT CLR ALL FIELDS", fields_with_all, ignore.case = TRUE)]

  # 4c. Compute total_actual, total_cleared, and clearance_rate
  clearance_summary <- clearance_raw %>%
    rowwise() %>%
    mutate(
      total_actual   = sum(c_across(all_of(actual_vars)), na.rm = TRUE),
      total_cleared  = sum(c_across(all_of(cleared_vars)), na.rm = TRUE),
      clearance_rate = if_else(total_actual > 0, total_cleared / total_actual * 100, NA_real_)
    ) %>%
    ungroup() %>%
    select(ORI = V3, total_actual, total_cleared, clearance_rate) %>%
    mutate(ORI = toupper(str_trim(ORI)))

  # 4d. Fuzzy join with academy list using ORI (Jaro-Winkler)
  matched <- academy_data %>%
    stringdist_left_join(
      clearance_summary,
      by = "ORI",
      method = "jw",
      max_dist = 0.1,
      distance_col = "match_dist"
    ) %>%
    arrange(row_id, match_dist) %>%
    group_by(row_id) %>%
    slice_min(match_dist, with_ties = FALSE) %>%
    ungroup() %>%
    select(-row_id, match_dist) %>%
    mutate(year = year)

  # 4e. Store matched data for export
  clearance_matches[[as.character(year)]] <- matched
}

# 5. Export final multi-sheet Excel file
write_xlsx(clearance_matches, path = "~/Downloads/roimatch2_clearance_enriched_2013_2018.xlsx")



//////////////////////////////////////KRUSKAL WALLACE///////////////////////////////////////
# 📦 Load required libraries
library(haven)
library(dplyr)
library(ggplot2)
library(ggsignif)
library(patchwork)

# 📥 Load dataset
data <- read_dta("~/Downloads/clean_subset.dta")

# 🏷️ Label agency_type3
data$agency_type3 <- factor(data$agency_type3,
                            levels = c(1, 2, 3),
                            labels = c("Traditional", "College", "Other"))

# 🎨 Color palette
fill_colors <- c("Traditional" = "#9ECAE1",
                 "College" = "#BCBDDC",
                 "Other" = "#D9D9D9")

# 📊 Pairwise comparisons
comparisons <- list(
  c("Traditional", "College"),
  c("Traditional", "Other"),
  c("College", "Other")
)

# 🧼 IQR-based outlier removal
remove_outliers <- function(df, variable, group_var) {
  df %>%
    group_by({{ group_var }}) %>%
    filter(
      !is.na({{ variable }}),
      {{ variable }} > quantile({{ variable }}, 0.25, na.rm = TRUE) - 1.5 * IQR({{ variable }}, na.rm = TRUE),
      {{ variable }} < quantile({{ variable }}, 0.75, na.rm = TRUE) + 1.5 * IQR({{ variable }}, na.rm = TRUE)
    ) %>%
    ungroup()
}

# 🧼 Cleaned datasets
clean_basic     <- remove_outliers(data, basic_lgth_hours, agency_type3)
clean_study     <- remove_outliers(data, total_studyhours, agency_type3)
clean_force     <- remove_outliers(data, force_based, agency_type3)
clean_special   <- remove_outliers(data, special_study, agency_type3)
clean_modern    <- remove_outliers(data, modern_study, agency_type3)
clean_inj       <- remove_outliers(data, total_inj, agency_type3)
clean_incidents <- remove_outliers(data, total_incidents, agency_type3)

# 🎨 Shared theme
themed <- theme_minimal() + theme(
  legend.position = "none",
  plot.title = element_text(hjust = 0.5),
  axis.text.x = element_text(size = 14, face = "bold")  # ✅ bold, large academy labels
)

# 📈 Training Plots
p1 <- ggplot(clean_basic, aes(x = agency_type3, y = basic_lgth_hours, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("***", "ns", "ns"), step_increase = 0.1) +
  labs(title = "Basic Training Hours", y = "Hours", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

p2 <- ggplot(clean_study, aes(x = agency_type3, y = total_studyhours, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("ns", "ns", "ns"), step_increase = 0.1) +
  labs(title = "Total Study Hours", y = "Hours", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

# 📈 Curriculum Plots
p3 <- ggplot(clean_force, aes(x = agency_type3, y = force_based, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("ns", "ns", "ns"), step_increase = 0.1) +
  labs(title = "Force-Based Instruction", y = "Hours", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

p4 <- ggplot(clean_special, aes(x = agency_type3, y = special_study, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("ns", "ns", "ns"), step_increase = 0.1) +
  labs(title = "Special Topics Instruction", y = "Hours", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

p5 <- ggplot(clean_modern, aes(x = agency_type3, y = modern_study, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("ns", "ns", "ns"), step_increase = 0.1) +
  labs(title = "Modern Policing Instruction", y = "Hours", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

# 📈 Injury + Incident Plots
p6 <- ggplot(clean_inj, aes(x = agency_type3, y = total_inj, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("***", "***", "ns"), step_increase = 0.1) +
  labs(title = "Total Injuries", y = "Count", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

p7 <- ggplot(clean_incidents, aes(x = agency_type3, y = total_incidents, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("***", "***", "ns"), step_increase = 0.1) +
  labs(title = "Total Incidents", y = "Count", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

# 💾 Save: Training Plot (600 DPI)
ggsave("~/Downloads/training_hours_comparison_outliers_removed.jpg",
       plot = (p1 | p2) + plot_layout(guides = "collect") & theme(legend.position = "bottom"),
       width = 14, height = 7, units = "in", dpi = 600)

# 💾 Save: Curriculum Plot (600 DPI)
ggsave("~/Downloads/curriculum_comparison_outliers_removed.jpg",
       plot = (p3 | p4 | p5) + plot_layout(guides = "collect") & theme(legend.position = "bottom"),
       width = 18, height = 7, units = "in", dpi = 600)

# 💾 Save: Injury + Incident Plot (600 DPI)
ggsave("~/Downloads/injury_incident_comparison_outliers_removed.jpg",
       plot = (p6 | p7) + plot_layout(guides = "collect") & theme(legend.position = "bottom"),
       width = 14, height = 7, units = "in", dpi = 600)
       
       
       # 📊 Kruskal-Wallis + Dunn tests for each cleaned variable
library(dunn.test)

run_kw_and_dunn <- function(df, yvar, label) {
  cat("\n\n==============================\n")
  cat("▶", label, "\n")
  cat("==============================\n\n")
  print(kruskal.test(df[[yvar]] ~ df$agency_type3))
  cat("\n🔍 Dunn Test (Bonferroni-adjusted):\n")
  print(dunn.test(df[[yvar]], df$agency_type3, method = "bonferroni"))
}

# 🧪 Run tests
run_kw_and_dunn(clean_basic,     "basic_lgth_hours",   "Basic Training Hours")
run_kw_and_dunn(clean_study,     "total_studyhours",   "Total Study Hours")
run_kw_and_dunn(clean_force,     "force_based",        "Force-Based Instruction")
run_kw_and_dunn(clean_special,   "special_study",      "Special Topics Instruction")
run_kw_and_dunn(clean_modern,    "modern_study",       "Modern Policing Instruction")
run_kw_and_dunn(clean_inj,       "total_inj",          "Total Injuries")
run_kw_and_dunn(clean_incidents, "total_incidents",    "Total Incidents")


//////////////////////////////////STATA/////////////////////////////

//////////////////////////////////////////CLEANING AND RECODING////////////////////////////////

// ADDITION OF TOTALS ACROSS ALL TYPES
egen total_inj = rowtotal(total_inj_firearms total_inj_knife total_inj_other total_inj_hands), missing
egen total_noninj = rowtotal(total_noninj_firearms total_noninj_knife total_noninj_other total_noninj_hands), missing
egen total_incidents = rowtotal (total_inj total_noninj), missing

* Total incidents involving firearms
egen total_firearms = rowtotal(total_inj_firearms total_noninj_firearms), missing

* Total incidents involving knives
egen total_knife    = rowtotal(total_inj_knife    total_noninj_knife),    missing

* Total incidents involving other weapons
egen total_other    = rowtotal(total_inj_other    total_noninj_other),    missing

* Total incidents involving hands (or unarmed)
egen total_hands    = rowtotal(total_inj_hands    total_noninj_hands),    missing


// ADDITION OF TOTALS ACROSS ALL TYPES

// Generate Total Officer Variable
egen total_officers = rowtotal(officers_women officer_men), missing

//Standardizing basic_lgth
* 1. Create a new variable for standardized hours
gen basic_lgth_hours = .

* 2. Keep original if already in hours
replace basic_lgth_hours = basic_lgth if basic_type == 1

* 3. Convert weeks to hours (5 business days × 8 hours/day = 40 hours/week)
replace basic_lgth_hours = basic_lgth * 40 if basic_type == 2

* 4. Convert months to hours (4.33 weeks/month × 5 business days/week × 8 hours/day = 173.2 hours/month)
replace basic_lgth_hours = basic_lgth * 173.2 if basic_type == 3

* 5. Convert semesters to hours (3 months × 173.2 hours/month = 519.6 hours/semester)
replace basic_lgth_hours = basic_lgth * 519.6 if basic_type == 4

* 6. Handle 'Other increment' and N/A: keep as missing
replace basic_lgth_hours = . if inlist(basic_type, 5, -8)

* Optional: check the distribution
summarize basic_lgth basic_lgth_hours

*Removing all non-batch variables*
keep order statecode academyname environment ft_sworn ft_civ ft_total pt_total eval_post eval_supe eval_stud refresher pat_yn pat judo_yn judo def_tac def_tac_yn fire_skill_yn fire_skill nonl_yn nonl field_man fitness_1 obstacle_1 scenario_1 simu_1 sex_start_total pt_civ pt_sworn comp_yn comp comm_yn comm stress_yn stress medi_yn medi domv_yn domv victim_yn victim post calea total_inj_firearms total_inj_knife total_inj_other total_inj_hands total_noninj_firearms total_noninj_knife total_noninj_other total_noninj_hands  gang gang_yn  pat judo_est def_tac_est fire_skill_est nonl_est comp_est comm_est stress_est medi_est domv_est victim victim_est gang_est min_exp ebudget opbudget agencyc agencycletatype basic_lgth field_lgth oversee min_ed req_post req_sme req_acad in_fire_1 out_fire_1 clab_1 int_1 media_1 dorm_1 opbudget_est ebudget_est sex_comp_total rno_total ori ori  state_nom population officer_men officers_women all_employees  stress  total_inj total_noninj total_actual total_cleared total_officers pat_yn prob_solv prob_solv_yn acsh_yn acsh basic_lgth_hours comm ethic health prof cult prob_solv crim jjl traf_law study com_part cult  prob_solv map comm ethic prof stress cpr comp emv evid intel intero inv pat rep traf judo def_tac fire_skill nonl crim_yn jjl_yn traf_law_yn study_yn com_part_yn cult_yn medi_yn prob_solv_yn map_yn comm_yn ethic_yn prof_yn stress_yn cpr_yn comp_yn emv_yn evid_yn intel_yn intero_yn inv_yn pat_yn rep_yn traf_yn judo_yn def_tac_yn fire_skill_yn nonl_yn health_yn dui dui_yn emr emr_yn htraf htraf_yn mental mental_yn opioid opioid_yn total_incidents total_firearms total_knife total_hands total_other

// Recode min_ed var
gen min_ed_cat = cond(min_ed == 1, 3, cond(inlist(min_ed, 2, 3), 2, cond(inlist(min_ed, 4, 5, 6), 1, .)))
label define min_ed_cat_lbl 1 "High school or less" 2 "College" 3 "Graduate", replace
label values min_ed_cat min_ed_cat_lbl

// both fire range access
gen any_fire_range = .
replace any_fire_range = 1 if in_fire_1 == 1 | out_fire_1 == 1
replace any_fire_range = 0 if in_fire_1 != . & out_fire_1 != . & in_fire_1 != 1 & out_fire_1 != 1


// Recode Agency type var/
gen agency_type3 = cond(inlist(agencycletatype, 1,2,3,4,5), 1, cond(inlist(agencycletatype, 6,7), 2, 3))
label define agency_type3_lbl 1 "Regular" 2 "College" 3 "Other", replace
label values agency_type3 agency_type3_lbl



foreach var in refresher pat_yn judo_yn def_tac_yn fire_skill_yn nonl_yn comp_yn gang_yn comm_yn stress_yn medi_yn domv_yn victim_yn eval_post eval_stud crim_yn jjl_yn traf_law_yn study_yn com_part_yn cult_yn prob_solv_yn map_yn ethic_yn prof_yn cpr_yn emv_yn evid_yn intel_yn intero_yn inv_yn rep_yn traf_yn health_yn dui_yn emr_yn htraf_yn mental_yn opioid_yn {
    replace `var' = 0 if `var' == 2
}


// Eliminate -8 observations to '.'
ds, has(type numeric)
foreach var of varlist `r(varlist)' {
    replace `var' = . if `var' == -8 
}
	
*Recode field_man*
recode field_man (1=3) (2=2) (3=1)

*Reverse Original Stress var/ recode ordinal var
recode environment (1=5) (2=4) (3=3) (4=2) (5=1)

gen environment_3 = .

replace environment_3 = 1 if inlist(environment, 4, 5)
replace environment_3 = 2 if environment == 3
replace environment_3 = 3 if inlist(environment, 1, 2)
label values environment_3 

* 0. Create instructor‐to‐cadet ratio
drop if (ft_total + pt_total) == 0
gen instructor_ratio = (ft_total + pt_total) / sex_start_total
label variable instructor_ratio 

*Create Clearance Rate var
drop if total_cleared == 0
drop if total_actual == 0

gen clearance_rate = .
replace clearance_rate = (total_cleared / total_actual) * 100 if total_actual > 0

	
// Aligned lists (hour variables and matching _yn indicators)
local vars     pat judo def_tac fire_skill nonl comp gang comm stress medi domv victim crim jjl traf_law study com_part cult prob_solv map ethic prof cpr emv evid intel intero inv rep traf health dui emr htraf mental opioid
local vars_yn  pat_yn judo_yn def_tac_yn fire_skill_yn nonl_yn comp_yn gang_yn comm_yn stress_yn medi_yn domv_yn victim_yn crim_yn jjl_yn traf_law_yn study_yn com_part_yn cult_yn prob_solv_yn map_yn ethic_yn prof_yn cpr_yn emv_yn evid_yn intel_yn intero_yn inv_yn rep_yn traf_yn health_yn dui_yn emr_yn htraf_yn mental_yn opioid_yn



local nvars : word count `vars'
forvalues i = 1/`nvars' {
    local v : word `i' of `vars'
    local vyn : word `i' of `vars_yn'
    replace `v' = 0 if `vyn' == 0
}


// 1️⃣ Create total training hours across selected subjects
egen total_studyhours = rowtotal(crim jjl traf_law study com_part cult medi prob_solv map comm ethic prof stress cpr comp emv evid intel intero inv pat rep traf judo def_tac fire_skill nonl opioid mental htraf emr dui gang)



// 2️⃣ Loop over each subject to compute proportion and high emphasis flag
foreach v in pat judo def_tac fire_skill nonl comp gang comm stress medi domv victim eval_post eval_stud crim jjl traf_law study com_part cult prob_solv map ethic prof cpr emv evid intel intero inv rep traf health dui emr htraf mental opioid {
    
    // Compute proportion of total training allocated to this subject
    gen `v'_prop = `v' / total_studyhours

    // Get median proportion across all observations
    quietly summarize `v'_prop
    local thresh = r(p50)

    // Create high emphasis indicator: 1 if proportion >= median, else 0
    gen byte `v'_high = `v'_prop >= `thresh'

    // Add descriptive label
    label variable `v'_high "`v': 1=High emphasis (≥ median share)"
}

///////////////////////////////////////////////////ANALYSIS/////////////////////////////////////////////////////

* -------------------------------------------
* LOAD DATA
* -------------------------------------------
use "/Users/nasseralsabah/Desktop/PhD/John Jay/Research/Academy/Analysis/STATA/GLM_Ready_May15(MULTI).dta", clear

drop if total_officers < 5

 summarize basic_lgth_hours environment_3 ft_sworn ft_civ min_ed_cat ///
    opbudget simu_1 scenario_1 obstacle_1  refresher  field_man agency_type3 ///
     simu_1 ///
    scenario_1 total_officers total_actual total_cleared 

drop if missing(basic_lgth_hours, environment_3, ft_sworn, ft_civ, min_ed_cat,  simu_1, scenario_1,  refresher,field_man, agency_type3, total_officers, total_actual, total_cleared, judo, def_tac, fire_skill, nonl, domv, mental, opioid, victim, comm ,prof, medi, prob_solv)
	
summarize basic_lgth_hours i.environment_3 ft_sworn ft_civ i.min_ed_cat refresher  i.field_man i.agency_type3 judo def_tac fire_skill nonl domv mental opioid victim comm prof medi prob_solv total_officers total_cleared total_actual total_hands total_knife total_firearms total_other total_incidents total_inj_hands total_inj_knife total_inj_firearms total_inj_other total_inj	

* -------------------------------------------
* Z-SCORE CONTINUOUS VARIABLES
* -------------------------------------------
summarize basic_lgth_hours
gen z_basic_lgth_hours = (basic_lgth_hours - r(mean)) / r(sd)

summarize ft_sworn
gen z_ft_sworn = (ft_sworn - r(mean)) / r(sd)

summarize ft_civ
gen z_ft_civ = (ft_civ - r(mean)) / r(sd)

summarize ebudget
gen z_ebudget = (ebudget - r(mean)) / r(sd)

summarize total_officers
gen z_total_officers = (total_officers - r(mean)) / r(sd)

summarize total_actual
gen z_total_actual = (total_actual - r(mean)) / r(sd)

summarize total_cleared
gen z_total_cleared = (total_cleared - r(mean)) / r(sd)


//Factor Analysis for Study Areas

factor judo def_tac fire_skill nonl 
predict force_based

factor domv mental opioid victim 
predict special_study

factor comm prof medi prob_solv 
predict modern_study

* -------------------------------------------
* TOTALS: total_inj + total_incidents (Cook's D applied correctly)
* -------------------------------------------
local dv_list " total_incidents total_firearms total_knife total_other total_hands"
eststo clear



foreach dv of local dv_list {
    di "---------------------------------------"
    di "Processing dependent variable: `dv'"

    preserve

    * Step 1: Initial model for Cook's D calculation
    quietly glm `dv' z_basic_lgth_hours ib2.environment_3 z_ft_sworn z_ft_civ ///
        i.min_ed_cat  simu_1 scenario_1 obstacle_1 refresher  ib3.field_man i.agency_type3 ///
        force_based special_study  modern_study simu_1  ///
        scenario_1  z_total_officers z_total_cleared z_total_actual, family(nbinomial) link(log)
		
    * Step 2: Cook's D filtering
    capture drop cooksd
    predict cooksd, cooksd
    scalar cutoff = 4 / e(N)
    di "Cook's D cutoff (4/N) = " %6.4f cutoff

    gen cleaned_`dv' = `dv'
    replace cleaned_`dv' = . if cooksd > cutoff

    tempfile temp_clean_`dv'
    save `temp_clean_`dv'', replace

    restore
    use `temp_clean_`dv'', clear

    * Step 3: Refit model on cleaned DV
    nbreg cleaned_`dv' z_basic_lgth_hours ib2.environment_3 z_ft_sworn z_ft_civ ///
        i.min_ed_cat   refresher  ib3.field_man i.agency_type3 ///
        force_based special_study  modern_study simu_1  ///
        scenario_1  z_total_officers z_total_cleared z_total_actual , irr
		

    estimates store m_`dv'
    eststo m_`dv'

  
}


* -------------------------------------------
* INJURY TYPES — Mixed Models: Binary (knife/firearms), Count + Cook's D (hands/other)
* -------------------------------------------
local dv_list "total_inj total_inj_hands total_inj_knife total_inj_firearms total_inj_other"
eststo clear

foreach dv of local dv_list {
    di as txt "---------------------------------------"
    di as txt "Processing dependent variable: `dv'"

    * CASE 1: Knife and Firearms — logit model, binary outcome, no Cook's D
    if inlist("`dv'", "total_inj_knife", "total_inj_firearms") {
        local binvar = subinstr("`dv'", "total_inj_", "binary_inj_", .)

        capture drop `binvar'
        gen `binvar' = (`dv' > 0) if !missing(`dv')

        logit `binvar' z_basic_lgth_hours ib2.environment_3 z_ft_sworn z_ft_civ ///
        i.min_ed_cat   refresher  ib3.field_man i.agency_type3 ///
        force_based special_study  modern_study simu_1  ///
        scenario_1  z_total_officers z_total_cleared z_total_actual , or
		
        estimates store m_`dv'
        eststo m_`dv'

    }

    * CASE 2: Hands and Other — count model, Cook's D applied
    else {
        preserve

        * Initial model (NBREG or Poisson)
        quietly glm `dv' z_basic_lgth_hours ib2.environment_3 z_ft_sworn z_ft_civ ///
        i.min_ed_cat   refresher  ib3.field_man i.agency_type3 ///
        force_based special_study  modern_study simu_1  ///
        scenario_1  z_total_officers z_total_cleared z_total_actual , family(nbinomial) link(log)


        * Cook's D
        capture drop cooksd
        predict cooksd, cooksd
        scalar cutoff = 4 / e(N)
        di as txt "Cook's D cutoff (4/N) = " %6.4f cutoff

        gen cleaned_`dv' = `dv'
        replace cleaned_`dv' = . if cooksd > cutoff

        tempfile temp_`dv'
        save `temp_`dv'', replace

        restore
        use `temp_`dv'', clear

        * Refit count model (NBREG or Poisson)
        nbreg cleaned_`dv' z_basic_lgth_hours ib2.environment_3 z_ft_sworn z_ft_civ ///
        i.min_ed_cat   refresher  ib3.field_man i.agency_type3 ///
        force_based special_study  modern_study simu_1  ///
        scenario_1  z_total_officers z_total_cleared z_total_actual , irr


        estimates store m_`dv'
        eststo m_`dv'

    }
}
