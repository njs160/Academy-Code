///////////////////////////////////////////R///////////////////////////////////////

//////////////////////////////////////ORI/OFFICER INJURY MERGE (2013-2018)///////////////////////////////////////

# enrich_academy_data_loop.R

# Load libraries
library(haven)       # for read_dta()
library(readr)       # for read_csv(), write_csv()
library(dplyr)
library(stringr)
library(fuzzyjoin)
library(stringdist)

# 1. Read and prepare roimatch1 and manual academy lookup
roimatch1 <- read_csv(
  "~/Downloads/roimatch1.csv",
  show_col_types = FALSE
) %>%
  rename(state_orig = statecode) %>%
  mutate(
    clean_academy = str_to_lower(academyname)
  )

# 1a. Manual city mappings for known exceptions
academy_lookup <- c(
  "university of alaska fairbanks community and technical" = "FAIRBANKS NORTH STAR BOROUGH",
  "alaska of public safety" = "SITKA",
  # ... (other mappings) ...
  "lubbock police department" = "LUBBOCK"
)

# 2. Clean roimatch1 academy names
roimatch1_clean <- roimatch1 %>%
  mutate(
    matched_city = academy_lookup[clean_academy],
    clean_academy = academyname %>%
      str_to_lower() %>%
      str_replace_all("\\b(police|training|academy|department|college|state|county|regional)\\b", " ") %>%
      str_replace_all("[^a-z]", " ") %>%
      str_squish()
  )

# 3. Define variables to select and rename
vars_to_select <- c(
  # ORI, identifiers
  "V3", "V9", "V10", "V11", "V12", "V15", "V18",
  # Injury by weapon groups
  paste0("V", c(74, 257, 440, 623, 806, 989, 1172, 1355, 1538, 1721, 1904, 2087)),
  paste0("V", c(75, 258, 441, 624, 807, 990, 1173, 1356, 1539, 1722, 1905, 2088)),
  paste0("V", c(76, 259, 442, 625, 808, 991, 1174, 1357, 1540, 1723, 1906, 2089)),
  paste0("V", c(77, 260, 443, 626, 809, 992, 1175, 1358, 1541, 1724, 1907, 2090)),
  # Non-injury by weapon groups
  paste0("V", c(79, 262, 445, 628, 811, 994, 1177, 1360, 1543, 1726, 1909, 2092)),
  paste0("V", c(80, 263, 446, 629, 812, 995, 1178, 1361, 1544, 1727, 1910, 2093)),
  paste0("V", c(81, 264, 447, 630, 813, 996, 1179, 1362, 1545, 1728, 1911, 2094)),
  paste0("V", c(82, 265, 448, 631, 814, 997, 1180, 1363, 1546, 1729, 1912, 2095)),
  # Killings
  paste0("V", c(72, 150, 333, 516, 699, 882, 1065, 1248, 1431, 1614, 1797, 1980)),
  paste0("V", c(73, 151, 334, 517, 700, 883, 1066, 1249, 1432, 1615, 1798, 1981))
)

# 4. Loop through years 2013 to 2018
for (yr in 2013:2018) {
  message("\nProcessing police_", yr, ".dta ...")

  # 4a. Read LEOK data for the year
  LEOK_data <- read_dta(sprintf("~/Downloads/police_%d.dta", yr)) %>%
    select(all_of(vars_to_select)) %>%
    rename(
      ori       = V3,
      city      = V10,
      state_nom = V11
    ) %>%
    mutate(
      statecode = toupper(substr(ori, 1, 2))
    )
  
  # 4b. Clean LEOK city names
  LEOK_clean <- LEOK_data %>%
    mutate(
      clean_city = city %>%
        str_to_lower() %>%
        str_replace_all("\\b(city|county)\\b", " ") %>%
        str_replace_all("[^a-z]", " ") %>%
        str_squish()
    )

  # 4c. Compute LEOK injury and killing totals
  LEOK_data <- LEOK_data %>%
    mutate(
      total_inj_firearms     = rowSums(across(paste0("V", c(74,257,440,623,806,989,1172,1355,1538,1721,1904,2087))), na.rm = TRUE),
      total_inj_knife        = rowSums(across(paste0("V", c(75,258,441,624,807,990,1173,1356,1539,1722,1905,2088))), na.rm = TRUE),
      total_inj_other        = rowSums(across(paste0("V", c(76,259,442,625,808,991,1174,1357,1540,1723,1906,2089))), na.rm = TRUE),
      total_inj_hands        = rowSums(across(paste0("V", c(77,260,443,626,809,992,1175,1358,1541,1724,1907,2090))), na.rm = TRUE),
      total_noninj_firearms  = rowSums(across(paste0("V", c(79,262,445,628,811,994,1177,1360,1543,1726,1909,2092))), na.rm = TRUE),
      total_noninj_knife     = rowSums(across(paste0("V", c(80,263,446,629,812,995,1178,1361,1544,1727,1910,2093))), na.rm = TRUE),
      total_noninj_other     = rowSums(across(paste0("V", c(81,264,447,630,813,996,1179,1362,1545,1728,1911,2094))), na.rm = TRUE),
      total_noninj_hands     = rowSums(across(paste0("V", c(82,265,448,631,814,997,1180,1363,1546,1729,1912,2095))), na.rm = TRUE),
      total_killed_felonious = rowSums(across(paste0("V", c(72,150,333,516,699,882,1065,1248,1431,1614,1797,1980))), na.rm = TRUE),
      total_killed_accidental= rowSums(across(paste0("V", c(73,151,334,517,700,883,1066,1249,1432,1615,1798,1981))), na.rm = TRUE)
    )

  # 4d. Fuzzy join roimatch1_clean and LEOK_clean, filter by state
  merged_raw <- stringdist_left_join(
    roimatch1_clean, LEOK_clean,
    by           = c("clean_academy" = "clean_city"),
    method       = "jw",
    max_dist     = 0.25,
    distance_col = "dist"
  ) %>%
    filter(toupper(state_orig) == statecode)

  # 4e. Select best matches
  matches_map <- merged_raw %>%
    group_by(academyname) %>%
    slice_min(dist, with_ties = FALSE) %>%
    ungroup() %>%
    transmute(academyname, matched_city = city)

  # 4f. Enrich and export
  enriched <- roimatch1_clean %>%
    left_join(matches_map, by = "academyname", suffix = c("", ".fuzzy")) %>%
    mutate(
      matched_city = coalesce(matched_city, matched_city.fuzzy)
    ) %>%
    select(-matched_city.fuzzy) %>%
    left_join(
      LEOK_data %>%
        select(
          ori, city, statecode,
          starts_with("total_inj_"), starts_with("total_noninj_"), starts_with("total_killed_")
        ),
      by = c("matched_city" = "city", "state_orig" = "statecode"),
      relationship = "many-to-many"
    ) %>%
    distinct(academyname, .keep_all = TRUE)

  # Write out CSV for this year
  write_csv(enriched, sprintf("~/Downloads/roimatch1_enriched(final%d).csv", yr))
}


//////////////////////////////////////CLEARANCE MERGE ///////////////////////////////////////
# //////////////////////////////////////ORI/CLEARANCE MERGE///////////////////////////////////////

# enrich_clearance_data.R

# Load libraries
library(haven)       # for read_dta()
library(readr)       # for read_csv()
library(dplyr)
library(stringr)
library(fuzzyjoin)
library(writexl)

# 1. Load and prepare academy ORI list
academy_data <- read_csv("~/Downloads/roimatch2.csv", show_col_types = FALSE) %>%
  rename(ORI = ori) %>%
  mutate(
    ORI = toupper(str_trim(ORI)),
    row_id = row_number()
  )

# 2. Define year range and file paths
years <- 2013:2018
file_paths <- paste0("~/Downloads/clearance_", years, ".dta")

# 3. Initialize results list for Excel export
clearance_matches <- list()

# 4. Loop through each clearance year
for (i in seq_along(years)) {
  year <- years[i]
  file <- file_paths[i]
  
  # 4a. Load clearance data
  clearance_raw <- read_dta(file)

  # 4b. Extract labels to find ACTUAL and CLEARED columns
  var_labels <- sapply(clearance_raw, function(x) attr(x, "label"), USE.NAMES = TRUE)
  fields_with_all <- var_labels[grepl("ALL FIELDS", var_labels, ignore.case = TRUE)]

  actual_vars    <- names(fields_with_all)[grepl("ACT # ALL FIELDS", fields_with_all, ignore.case = TRUE)]
  cleared_vars   <- names(fields_with_all)[grepl("TOT CLR ALL FIELDS", fields_with_all, ignore.case = TRUE)]

  # 4c. Compute total_actual, total_cleared, and clearance_rate
  clearance_summary <- clearance_raw %>%
    rowwise() %>%
    mutate(
      total_actual   = sum(c_across(all_of(actual_vars)), na.rm = TRUE),
      total_cleared  = sum(c_across(all_of(cleared_vars)), na.rm = TRUE),
      clearance_rate = if_else(total_actual > 0, total_cleared / total_actual * 100, NA_real_)
    ) %>%
    ungroup() %>%
    select(ORI = V3, total_actual, total_cleared, clearance_rate) %>%
    mutate(ORI = toupper(str_trim(ORI)))

  # 4d. Fuzzy join with academy list using ORI (Jaro-Winkler)
  matched <- academy_data %>%
    stringdist_left_join(
      clearance_summary,
      by = "ORI",
      method = "jw",
      max_dist = 0.1,
      distance_col = "match_dist"
    ) %>%
    arrange(row_id, match_dist) %>%
    group_by(row_id) %>%
    slice_min(match_dist, with_ties = FALSE) %>%
    ungroup() %>%
    select(-row_id, match_dist) %>%
    mutate(year = year)

  # 4e. Store matched data for export
  clearance_matches[[as.character(year)]] <- matched
}

# 5. Export final multi-sheet Excel file
write_xlsx(clearance_matches, path = "~/Downloads/roimatch2_clearance_enriched_2013_2018.xlsx")



//////////////////////////////////////KRUSKAL WALLACE///////////////////////////////////////
# ðŸ“¦ Load required libraries
library(haven)
library(dplyr)
library(ggplot2)
library(ggsignif)
library(patchwork)

# ðŸ“¥ Load dataset
data <- read_dta("~/Downloads/clean_subset.dta")

# ðŸ·ï¸ Label agency_type3
data$agency_type3 <- factor(data$agency_type3,
                            levels = c(1, 2, 3),
                            labels = c("Traditional", "College", "Other"))

# ðŸŽ¨ Color palette
fill_colors <- c("Traditional" = "#9ECAE1",
                 "College" = "#BCBDDC",
                 "Other" = "#D9D9D9")

# ðŸ“Š Pairwise comparisons
comparisons <- list(
  c("Traditional", "College"),
  c("Traditional", "Other"),
  c("College", "Other")
)

# ðŸ§¼ IQR-based outlier removal
remove_outliers <- function(df, variable, group_var) {
  df %>%
    group_by({{ group_var }}) %>%
    filter(
      !is.na({{ variable }}),
      {{ variable }} > quantile({{ variable }}, 0.25, na.rm = TRUE) - 1.5 * IQR({{ variable }}, na.rm = TRUE),
      {{ variable }} < quantile({{ variable }}, 0.75, na.rm = TRUE) + 1.5 * IQR({{ variable }}, na.rm = TRUE)
    ) %>%
    ungroup()
}

# ðŸ§¼ Cleaned datasets
clean_basic     <- remove_outliers(data, basic_lgth_hours, agency_type3)
clean_study     <- remove_outliers(data, total_studyhours, agency_type3)
clean_force     <- remove_outliers(data, force_based, agency_type3)
clean_special   <- remove_outliers(data, special_study, agency_type3)
clean_modern    <- remove_outliers(data, modern_study, agency_type3)
clean_inj       <- remove_outliers(data, total_inj, agency_type3)
clean_incidents <- remove_outliers(data, total_incidents, agency_type3)

# ðŸŽ¨ Shared theme
themed <- theme_minimal() + theme(
  legend.position = "none",
  plot.title = element_text(hjust = 0.5),
  axis.text.x = element_text(size = 14, face = "bold")  # âœ… bold, large academy labels
)

# ðŸ“ˆ Training Plots
p1 <- ggplot(clean_basic, aes(x = agency_type3, y = basic_lgth_hours, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("***", "ns", "ns"), step_increase = 0.1) +
  labs(title = "Basic Training Hours", y = "Hours", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

p2 <- ggplot(clean_study, aes(x = agency_type3, y = total_studyhours, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("ns", "ns", "ns"), step_increase = 0.1) +
  labs(title = "Total Study Hours", y = "Hours", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

# ðŸ“ˆ Curriculum Plots
p3 <- ggplot(clean_force, aes(x = agency_type3, y = force_based, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("ns", "ns", "ns"), step_increase = 0.1) +
  labs(title = "Force-Based Instruction", y = "Hours", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

p4 <- ggplot(clean_special, aes(x = agency_type3, y = special_study, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("ns", "ns", "ns"), step_increase = 0.1) +
  labs(title = "Special Topics Instruction", y = "Hours", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

p5 <- ggplot(clean_modern, aes(x = agency_type3, y = modern_study, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("ns", "ns", "ns"), step_increase = 0.1) +
  labs(title = "Modern Policing Instruction", y = "Hours", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

# ðŸ“ˆ Injury + Incident Plots
p6 <- ggplot(clean_inj, aes(x = agency_type3, y = total_inj, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("***", "***", "ns"), step_increase = 0.1) +
  labs(title = "Total Injuries", y = "Count", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

p7 <- ggplot(clean_incidents, aes(x = agency_type3, y = total_incidents, fill = agency_type3)) +
  geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.4, color = "black") +
  geom_signif(comparisons = comparisons, annotations = c("***", "***", "ns"), step_increase = 0.1) +
  labs(title = "Total Incidents", y = "Count", x = NULL) +
  scale_fill_manual(values = fill_colors, guide = "none") + themed

# ðŸ’¾ Save: Training Plot (600 DPI)
ggsave("~/Downloads/training_hours_comparison_outliers_removed.jpg",
       plot = (p1 | p2) + plot_layout(guides = "collect") & theme(legend.position = "bottom"),
       width = 14, height = 7, units = "in", dpi = 600)

# ðŸ’¾ Save: Curriculum Plot (600 DPI)
ggsave("~/Downloads/curriculum_comparison_outliers_removed.jpg",
       plot = (p3 | p4 | p5) + plot_layout(guides = "collect") & theme(legend.position = "bottom"),
       width = 18, height = 7, units = "in", dpi = 600)

# ðŸ’¾ Save: Injury + Incident Plot (600 DPI)
ggsave("~/Downloads/injury_incident_comparison_outliers_removed.jpg",
       plot = (p6 | p7) + plot_layout(guides = "collect") & theme(legend.position = "bottom"),
       width = 14, height = 7, units = "in", dpi = 600)
       
       
       # ðŸ“Š Kruskal-Wallis + Dunn tests for each cleaned variable
library(dunn.test)

run_kw_and_dunn <- function(df, yvar, label) {
  cat("\n\n==============================\n")
  cat("â–¶", label, "\n")
  cat("==============================\n\n")
  print(kruskal.test(df[[yvar]] ~ df$agency_type3))
  cat("\nðŸ” Dunn Test (Bonferroni-adjusted):\n")
  print(dunn.test(df[[yvar]], df$agency_type3, method = "bonferroni"))
}

# ðŸ§ª Run tests
run_kw_and_dunn(clean_basic,     "basic_lgth_hours",   "Basic Training Hours")
run_kw_and_dunn(clean_study,     "total_studyhours",   "Total Study Hours")
run_kw_and_dunn(clean_force,     "force_based",        "Force-Based Instruction")
run_kw_and_dunn(clean_special,   "special_study",      "Special Topics Instruction")
run_kw_and_dunn(clean_modern,    "modern_study",       "Modern Policing Instruction")
run_kw_and_dunn(clean_inj,       "total_inj",          "Total Injuries")
run_kw_and_dunn(clean_incidents, "total_incidents",    "Total Incidents")


