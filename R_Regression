# COMPLETE NEGATIVE BINOMIAL ANALYSIS WITH COOK'S D FOR ALL OUTCOMES
# ===================================================================

# Clear workspace
rm(list = ls())

# Load ALL required libraries first
library(mice)       # For multiple imputation
library(dplyr)      # For data manipulation
library(psych)      # For factor analysis
library(MASS)       # For negative binomial
library(pscl)       # For zero-inflated models
library(lmtest)     # For likelihood ratio tests
library(AER)        # For dispersion tests
library(performance)# For model diagnostics
library(texreg)     # For regression tables
library(ggplot2)    # For visualization
library(car)        # For VIF
library(lavaan)     # For CFA
library(semTools)   # For CFA tools
library(openxlsx)   # For Excel export

# Set paths
save_path <- "/Users/nasseralsabah/Desktop/PhD/John Jay/Research/Academy/Post-Leoka (Second)/Analysis/R/"
downloads_path <- "~/Downloads/"

# Load and prepare data
file_path <- paste0(save_path, "Post_ImputedAug2_R.RData")
cat("Loading data from:", file_path, "\n")
load(file_path)
data_final <- data_imputed

cat("\n✓ Data loaded successfully\n")
cat("Dimensions:", nrow(data_final), "rows x", ncol(data_final), "columns\n")
cat("Number of imputations:", max(data_final$.imp), "\n")
cat("Observations per imputation:", nrow(data_final[data_final$.imp == 1, ]), "\n")

# Set working directory
setwd(save_path)

#-------------------------------------------
# DEFINE HELPER FUNCTIONS
#-------------------------------------------

pooled_nb_regression_enhanced <- function(mi_data, outcome_var, predictors) {
  n_imp <- max(mi_data$.imp)
  model_list <- list()
  theta_values <- numeric(n_imp)
  aic_values <- numeric(n_imp)
  bic_values <- numeric(n_imp)
  
  for(i in 1:n_imp) {
    imp_data <- mi_data[mi_data$.imp == i, ]
    formula_str <- paste(outcome_var, "~", paste(predictors, collapse = " + "))
    formula_obj <- as.formula(formula_str)
    
    tryCatch({
      model <- glm.nb(formula_obj, data = imp_data)
      model_list[[i]] <- model
      theta_values[i] <- model$theta
      aic_values[i] <- AIC(model)
      bic_values[i] <- BIC(model)
    }, error = function(e) {
      cat("  Error in imputation", i, ":", e$message, "\n")
      return(NULL)
    })
  }
  
  if(length(model_list) == 0) return(NULL)
  
  # Pool results using Rubin's rules
  n_params <- length(coef(model_list[[1]]))
  pooled_estimates <- numeric(n_params)
  pooled_se <- numeric(n_params)
  param_names <- names(coef(model_list[[1]]))
  
  for(j in 1:n_params) {
    estimates <- sapply(model_list, function(m) if(!is.null(m)) coef(m)[j] else NA)
    variances <- sapply(model_list, function(m) if(!is.null(m)) vcov(m)[j,j] else NA)
    
    valid_estimates <- estimates[!is.na(estimates)]
    valid_variances <- variances[!is.na(variances)]
    n_valid <- length(valid_estimates)
    
    if(n_valid > 0) {
      pooled_estimates[j] <- mean(valid_estimates)
      within_var <- mean(valid_variances)
      between_var <- if(n_valid > 1) var(valid_estimates) else 0
      total_var <- within_var + between_var + between_var/n_valid
      pooled_se[j] <- sqrt(total_var)
    } else {
      pooled_estimates[j] <- NA
      pooled_se[j] <- NA
    }
  }
  
  # Create summary dataframe
  summary_df <- data.frame(
    term = param_names,
    estimate = pooled_estimates,
    std.error = pooled_se,
    statistic = pooled_estimates / pooled_se,
    p.value = 2 * pnorm(-abs(pooled_estimates / pooled_se)),
    IRR = exp(pooled_estimates),
    IRR.lower = exp(pooled_estimates - 1.96 * pooled_se),
    IRR.upper = exp(pooled_estimates + 1.96 * pooled_se),
    stringsAsFactors = FALSE
  )
  
  summary_df$stars <- case_when(
    summary_df$p.value < 0.001 ~ "***",
    summary_df$p.value < 0.01 ~ "**",
    summary_df$p.value < 0.05 ~ "*",
    summary_df$p.value < 0.1 ~ "†",
    TRUE ~ ""
  )
  
  # Calculate pseudo R-squared
  imp1_data <- mi_data[mi_data$.imp == 1, ]
  null_model <- tryCatch({
    glm.nb(as.formula(paste(outcome_var, "~ 1")), data = imp1_data)
  }, error = function(e) NULL)
  
  if(!is.null(null_model)) {
    avg_loglik_full <- mean(sapply(model_list, function(m) if(!is.null(m)) logLik(m) else NA), na.rm = TRUE)
    loglik_null <- logLik(null_model)
    n_obs <- nrow(imp1_data)
    mcfadden <- 1 - (avg_loglik_full / loglik_null)
    cox_snell <- 1 - exp(-2 * (avg_loglik_full - loglik_null) / n_obs)
    nagelkerke <- cox_snell / (1 - exp(2 * loglik_null / n_obs))
  } else {
    mcfadden <- NA
    cox_snell <- NA
    nagelkerke <- NA
    n_obs <- nrow(imp1_data)
  }
  
  return(list(
    summary = summary_df,
    pseudo_r2 = list(
      mcfadden = mcfadden,
      cox_snell = cox_snell,
      nagelkerke = nagelkerke
    ),
    avg_theta = mean(theta_values, na.rm = TRUE),
    avg_aic = mean(aic_values, na.rm = TRUE),
    avg_bic = mean(bic_values, na.rm = TRUE),
    n_obs = n_obs,
    n_imp = n_imp
  ))
}

cook_d_cleaning <- function(data, outcomes, predictors) {
  if(".imp" %in% names(data)) {
    imp_nums <- unique(data$.imp)
    imp_nums <- imp_nums[imp_nums > 0]
  } else {
    imp_nums <- 1
    data$.imp <- 1
  }
  
  for(dv in outcomes) {
    if(dv %in% names(data)) {
      print(paste(">>> Processing Cook's D for", dv))
      
      data[[paste0("cooksd_", dv)]] <- NA
      data[[paste0("cleaned_", dv)]] <- data[[dv]]
      
      for(m in imp_nums) {
        mask <- data$.imp == m
        subset_data <- data[mask, c(dv, predictors), drop = FALSE]
        complete_cases <- complete.cases(subset_data)
        
        if(sum(complete_cases) > length(predictors) + 1) {
          N <- sum(complete_cases)
          cutoff <- 4 / N
          
          tryCatch({
            formula_str <- paste(dv, "~", paste(predictors, collapse = " + "))
            model <- lm(as.formula(formula_str), data = subset_data[complete_cases, ])
            cooksd_values <- cooks.distance(model)
            
            cooksd_full <- rep(NA, sum(mask))
            cooksd_full[complete_cases] <- cooksd_values
            data[[paste0("cooksd_", dv)]][mask] <- cooksd_full
            
            high_influence <- cooksd_full > cutoff & !is.na(cooksd_full)
            data[[paste0("cleaned_", dv)]][mask][high_influence] <- NA
            
            print(paste("  Imputation", m, ": Removed", sum(high_influence, na.rm = TRUE), 
                       "high-influence cases out of", N, "(cutoff =", round(cutoff, 6), ")"))
            
          }, error = function(e) {
            warning(paste("Cook's D calculation failed for", dv, "in imputation", m, ":", e$message))
          })
        }
      }
    }
  }
  
  return(data)
}

calculate_avg_n <- function(data, outcome_var) {
  n_imp <- max(data$.imp)
  n_per_imp <- numeric(n_imp)
  
  for(i in 1:n_imp) {
    imp_data <- data[data$.imp == i, ]
    n_per_imp[i] <- sum(!is.na(imp_data[[outcome_var]]))
  }
  
  return(round(mean(n_per_imp)))
}

# Fixed VIF calculation function
calculate_pooled_vif <- function(data, predictors) {
  cat("\n=== VARIANCE INFLATION FACTOR (VIF) CHECK ===\n")
  cat("Checking for multicollinearity across imputations...\n\n")
  
  # Get first imputation data
  imp1_data <- data[data$.imp == 1, ]
  
  # Select only the predictors we need
  vif_data <- imp1_data[, predictors, drop = FALSE]
  
  # Remove rows with any missing values
  vif_data <- vif_data[complete.cases(vif_data), ]
  
  # Create a fake outcome variable
  vif_data$fake_y <- rnorm(nrow(vif_data))
  
  # Create formula
  formula_str <- paste("fake_y ~", paste(predictors, collapse = " + "))
  
  # Fit model
  tryCatch({
    model <- lm(as.formula(formula_str), data = vif_data)
    
    # Calculate VIF - handle both regular and GVIF for factors
    vif_raw <- vif(model)
    
    # Check if we have GVIF (for factors with >2 levels)
    if(is.matrix(vif_raw)) {
      # For factors, use GVIF^(1/(2*Df))
      vif_values <- vif_raw[, "GVIF^(1/(2*Df))"]^2  # Square to get comparable values
      names(vif_values) <- rownames(vif_raw)
    } else {
      vif_values <- vif_raw
    }
    
    # Create summary table
    vif_summary <- data.frame(
      Predictor = names(vif_values),
      VIF = round(vif_values, 2),
      stringsAsFactors = FALSE
    )
    
    # Sort by VIF value
    vif_summary <- vif_summary[order(vif_summary$VIF, decreasing = TRUE), ]
    
    # Print results
    print(vif_summary, row.names = FALSE)
    
    # Identify problematic predictors
    high_vif <- vif_summary$VIF > 10
    if(any(high_vif)) {
      cat("\n⚠ WARNING: The following predictors have VIF > 10:\n")
      print(vif_summary[high_vif, ], row.names = FALSE)
    } else {
      cat("\n✓ All VIF values are below 10 (no severe multicollinearity detected)\n")
    }
    
    moderate_vif <- vif_summary$VIF > 5 & vif_summary$VIF <= 10
    if(any(moderate_vif)) {
      cat("\n⚠ Note: The following predictors have VIF between 5-10 (moderate multicollinearity):\n")
      print(vif_summary[moderate_vif, ], row.names = FALSE)
    }
    
    return(vif_summary)
    
  }, error = function(e) {
    cat("Error calculating VIF:", e$message, "\n")
    
    # Try alternative approach - calculate correlation matrix for numeric variables
    cat("\nAttempting correlation-based diagnostics for numeric variables...\n")
    
    # Get only numeric predictors
    numeric_preds <- predictors[sapply(vif_data[predictors], is.numeric)]
    
    if(length(numeric_preds) > 1) {
      cor_matrix <- cor(vif_data[numeric_preds], use = "complete.obs")
      
      # Find high correlations
      high_cor <- which(abs(cor_matrix) > 0.7 & cor_matrix != 1, arr.ind = TRUE)
      
      if(nrow(high_cor) > 0) {
        cat("\nHigh correlations (|r| > 0.7) found between:\n")
        for(i in 1:nrow(high_cor)) {
          if(high_cor[i, 1] < high_cor[i, 2]) {  # Only print each pair once
            cat(sprintf("  %s <-> %s: r = %.3f\n",
                       rownames(cor_matrix)[high_cor[i, 1]],
                       colnames(cor_matrix)[high_cor[i, 2]],
                       cor_matrix[high_cor[i, 1], high_cor[i, 2]]))
          }
        }
      } else {
        cat("\nNo high correlations (|r| > 0.7) found among numeric predictors.\n")
      }
    }
    
    return(NULL)
  })
}

# Drop unwanted variables
drop_vars <- c("train_inserv", "train_special", "train_first", "train_field", "train_lateral", 
               "train_pre", "train_night", "train_reserve", "pos_local", "pos_sher", "pos_camp", 
               "pos_corr", "pos_ranger", "pos_sro", "pos_hwy", "pos_aux", "pos_pre", "pos_nat", 
               "pos_arson", "pos_constable", "pos_transport", "pos_tribe", "pos_mar", "rno_self", 
               "rno_local", "rno_sher", "rno_state", "rno_special", "rno_total")

data_final <- data_final[, !names(data_final) %in% drop_vars]

#-------------------------------------------
# CREATE OUTCOME VARIABLES
#-------------------------------------------

# Create total incidents by weapon type
data_final <- data_final %>%
  mutate(
    total_firearms = total_inj_firearms + total_noninj_firearms,
    total_knife = total_inj_knife + total_noninj_knife,
    total_other = total_inj_other + total_noninj_other,
    total_hands = total_inj_hands + total_noninj_hands,
    total_injuries = total_inj_firearms + total_inj_knife + total_inj_other + total_inj_hands,
    total_incidents = total_firearms + total_knife + total_other + total_hands
  )

#-------------------------------------------
# CREATE PREDICTOR VARIABLES
#-------------------------------------------

# Instructor ratio
data_final$instructor_ratio <- (data_final$ft_total + data_final$pt_total) / data_final$sex_start_total

# Total training hours
training_subjects <- c("crim", "jjl", "traf_law", "study", "com_part", "cult", "medi", 
                       "prob_solv", "map", "comm", "ethic", "prof", "stress", "cpr", 
                       "comp", "emv", "evid", "intel", "intero", "inv", "pat", "rep", 
                       "traf", "judo", "def_tac", "fire_skill", "nonl", "victim", 
                       "domv", "opioid", "mental", "htraf", "emr", "dui", "gang")

data_final$total_studyhours <- rowSums(data_final[training_subjects], na.rm = TRUE)

# Fail metrics
data_final$eth_completion_rate <- data_final$eth_comp_total / data_final$eth_start_total
data_final$fail_phys_total <- data_final$fail_phys_m + data_final$fail_phys_f
data_final$fail_academic_total <- data_final$fail_acad_m + data_final$fail_acad_f
# NOT creating fail_total as requested

# Firearm range
data_final$firerange <- as.numeric(data_final$in_fire_1 == 1 | data_final$out_fire_1 == 1)

# UCR data
data_final$total_clearviolent <- data_final$total_cleared_murder + data_final$total_cleared_robbery + 
                                 data_final$total_cleared_assault + data_final$total_cleared_burglary

data_final$violentclearance_rate <- ifelse(data_final$total_violent > 0, 
                                           (data_final$total_clearviolent / data_final$total_violent) * 100, 
                                           NA)

#-------------------------------------------
# REMOVE CLEARANCE RATE OUTLIERS
#-------------------------------------------

cat("\n=== REMOVING CLEARANCE RATE OUTLIERS ===\n")
original_rows <- nrow(data_final)
data_imp1 <- data_final[data_final$.imp == 1, ]
high_clearance_mask <- !is.na(data_imp1$violentclearance_rate) & data_imp1$violentclearance_rate > 100

if(sum(high_clearance_mask) > 0) {
  problem_ids <- data_imp1$.id[high_clearance_mask]
  cat("Found", length(problem_ids), "observations with clearance rate > 100%\n")
  data_final <- data_final[!data_final$.id %in% problem_ids, ]
  cat("After removal:", nrow(data_final[data_final$.imp == 1, ]), "observations per imputation\n")
}

#-------------------------------------------
# KEEP ONLY NEEDED VARIABLES
#-------------------------------------------

keeplist <- c(
  ".imp", ".id",
  "total_firearms", "total_knife", "total_other", "total_hands",
  "fail_phys_total", "fail_academic_total", "eth_comp_total",
  "total_inj_hands", "total_inj_knife", "total_inj_firearms", "total_inj_other",
  "total_injuries", "total_incidents",
  "instructor_ratio",
  "basic_lgth_hours", "ft_sworn", "ft_civ", "ebudget", "opbudget", "mean_officers",
  "total_studyhours", "total_violent", "field_man", "environment_3", "agency_type3", "min_ed_bin",
  "fitness_1", "obstacle_1", "firerange", "scenario_1", "refresher",
  "htraf", "emv", "pat", "judo", "def_tac", "fire_skill", "nonl",
  "medi", "prob_solv", "comm", "ethic", "stress", "prof", "cult",
  "crim", "jjl", "traf_law", "domv", "gang", "victim", "com_part",
  "total_cleared_murder", "total_cleared_robbery", "total_cleared_assault", "total_cleared_burglary",
  "total_clearviolent", "violentclearance_rate",
  "statecode"
)

keeplist <- keeplist[keeplist %in% names(data_final)]
data_final <- data_final[, keeplist]

#-------------------------------------------
# Z-SCORE STANDARDIZATION
#-------------------------------------------

standardize_vars <- c("basic_lgth_hours", "ft_sworn", "ft_civ", "ebudget", "opbudget", 
                     "mean_officers", "total_studyhours", "total_violent", "total_clearviolent",
                     "fail_phys_total", "fail_academic_total")
# Removed "fail_total" from standardization

standardize_imputed <- function(data, vars) {
  if(".imp" %in% names(data)) {
    imp_nums <- unique(data$.imp)
  } else {
    imp_nums <- 0
  }
  
  for(var in vars) {
    if(var %in% names(data)) {
      z_var_name <- paste0("z_", var)
      data[[z_var_name]] <- NA
      
      for(imp in imp_nums) {
        if(".imp" %in% names(data)) {
          mask <- data$.imp == imp
        } else {
          mask <- rep(TRUE, nrow(data))
        }
        
        values <- data[[var]][mask]
        if(sum(!is.na(values)) > 1) {
          data[[z_var_name]][mask] <- scale(values)[,1]
        }
      }
    }
  }
  return(data)
}

data_final <- standardize_imputed(data_final, standardize_vars)

#-------------------------------------------
# CONVERT CATEGORICAL VARIABLES TO FACTORS
#-------------------------------------------

if("field_man" %in% names(data_final)) {
  data_final$field_man <- as.factor(data_final$field_man)
  if("3" %in% levels(data_final$field_man)) {
    data_final$field_man <- relevel(data_final$field_man, ref = "3")
  }
}

if("environment_3" %in% names(data_final)) {
  data_final$environment_3 <- as.factor(data_final$environment_3)
  if("2" %in% levels(data_final$environment_3)) {
    data_final$environment_3 <- relevel(data_final$environment_3, ref = "2")
  }
}

if("agency_type3" %in% names(data_final)) {
  data_final$agency_type3 <- as.factor(data_final$agency_type3)
}

# Create binary overseeing agency variable (college vs traditional)
# Collapse "Other" (3) into "Traditional" (1)
data_final$agency_college <- ifelse(data_final$agency_type3 == "2", 1, 0)

#-------------------------------------------
# FACTOR SCORE GENERATION (CFA)
#-------------------------------------------

perform_cfa_analysis <- function(data, vars, factor_name) {
  if(".imp" %in% names(data)) {
    imp_nums <- unique(data$.imp)
  } else {
    imp_nums <- 0
  }
  
  data[[factor_name]] <- NA
  all_fit_indices <- list()
  
  for(imp in imp_nums) {
    if(".imp" %in% names(data)) {
      mask <- data$.imp == imp
      subset_data <- data[mask, vars, drop = FALSE]
    } else {
      subset_data <- data[, vars, drop = FALSE]
      mask <- rep(TRUE, nrow(data))
    }
    
    complete_cases <- complete.cases(subset_data)
    if(sum(complete_cases) > length(vars)) {
      cfa_data <- subset_data[complete_cases, , drop = FALSE]
      
      items <- paste(vars, collapse = " + ")
      cfa_model <- paste0(factor_name, " =~ ", items)
      
      tryCatch({
        cfa_fit <- cfa(cfa_model, data = cfa_data, std.lv = TRUE, estimator = "MLR")
        fit_indices <- fitMeasures(cfa_fit, c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", 
                                              "rmsea.ci.lower", "rmsea.ci.upper", "srmr"))
        all_fit_indices[[length(all_fit_indices) + 1]] <- fit_indices
        
        factor_scores <- rep(NA, sum(mask))
        factor_scores[complete_cases] <- lavPredict(cfa_fit, method = "regression")[,1]
        data[[factor_name]][mask] <- factor_scores
        
      }, error = function(e) {
        warning(paste("CFA failed for", factor_name, "in imputation", imp))
        
        tryCatch({
          fa_result <- fa(cfa_data, nfactors = 1, rotate = "none", scores = "regression")
          factor_scores <- rep(NA, sum(mask))
          factor_scores[complete_cases] <- fa_result$scores[,1]
          data[[factor_name]][mask] <- factor_scores
        }, error = function(e2) {
          warning(paste("Both CFA and EFA failed for", factor_name, "in imputation", imp))
        })
      })
    }
  }
  
  return(data)
}

cat("\n=== CREATING FACTOR SCORES ===\n")

# Force-based Instruction
force_vars <- c("emv", "def_tac", "fire_skill", "nonl")
force_vars <- force_vars[force_vars %in% names(data_final)]
if(length(force_vars) > 0) {
  data_final <- perform_cfa_analysis(data_final, force_vars, "force_based")
}

# Contemporary Policing Studies
modern_vars <- c("comm", "ethic", "prof", "cult")
modern_vars <- modern_vars[modern_vars %in% names(data_final)]
if(length(modern_vars) > 0) {
  data_final <- perform_cfa_analysis(data_final, modern_vars, "contemporary_policing")
  temp_data <- data_final[, modern_vars]
  data_final$contemporary_policing_composite <- rowMeans(temp_data, na.rm = TRUE)
}

# Special Topics Study
special_vars <- c("jjl", "traf_law", "domv", "victim")
special_vars <- special_vars[special_vars %in% names(data_final)]
if(length(special_vars) > 0) {
  data_final <- perform_cfa_analysis(data_final, special_vars, "special_study")
}

#-------------------------------------------
# DEFINE PREDICTORS
#-------------------------------------------

# Standard predictors for all models
preds_full <- c(
  "z_basic_lgth_hours",
  "field_man",
  "environment_3",
  "z_ebudget", 
  "z_opbudget",
  "agency_type3",
  "fitness_1", 
  "obstacle_1", 
  "firerange", 
  "scenario_1", 
  "refresher",
  "force_based", 
  "contemporary_policing_composite",
  "special_study",
  "z_ft_sworn", 
  "z_ft_civ",
  "min_ed_bin", 
  "z_mean_officers", 
  "z_total_violent",
  "violentclearance_rate",
  "z_fail_phys_total",
  "z_fail_academic_total"
  # REMOVED: "z_fail_total"
)

# Special predictors for firearms injuries model (binary college variable)
preds_firearms_injuries <- c(
  "z_basic_lgth_hours",
  "field_man",
  "environment_3",
  "z_ebudget", 
  "z_opbudget",
  "agency_college",  # Binary variable instead of agency_type3
  "fitness_1", 
  "obstacle_1", 
  "firerange", 
  "scenario_1", 
  "refresher",
  "force_based", 
  "contemporary_policing_composite",
  "special_study",
  "z_ft_sworn", 
  "z_ft_civ",
  "min_ed_bin", 
  "z_mean_officers", 
  "z_total_violent",
  "violentclearance_rate",
  "z_fail_phys_total",
  "z_fail_academic_total"
)

preds_full <- preds_full[preds_full %in% names(data_final)]
preds_firearms_injuries <- preds_firearms_injuries[preds_firearms_injuries %in% names(data_final)]

#-------------------------------------------
# RUN VIF CHECK BEFORE MODELS
#-------------------------------------------

# Check VIF for standard predictors
vif_results <- calculate_pooled_vif(data_final, preds_full)

# Check VIF for firearms injuries predictors
cat("\n\n=== VIF CHECK FOR FIREARMS INJURIES MODEL ===\n")
vif_results_firearms <- calculate_pooled_vif(data_final, preds_firearms_injuries)

#-------------------------------------------
# APPLY COOK'S D TO ALL OUTCOMES
#-------------------------------------------

cat("\n=== APPLYING COOK'S D TO ALL OUTCOMES ===\n")

injury_dvs <- c("total_inj_firearms", "total_inj_knife", "total_inj_other", "total_inj_hands", "total_injuries")
incident_dvs <- c("total_firearms", "total_knife", "total_other", "total_hands", "total_incidents")
all_dvs <- c(injury_dvs, incident_dvs)

preds_cooksd <- c("z_basic_lgth_hours", "z_ft_sworn", "z_ft_civ", "z_ebudget", "z_opbudget", "z_mean_officers")

data_final <- cook_d_cleaning(data_final, all_dvs, preds_cooksd)

cleaned_injury_outcomes <- paste0("cleaned_", injury_dvs)
cleaned_incident_outcomes <- paste0("cleaned_", incident_dvs)

#-------------------------------------------
# CREATE REGIONS
#-------------------------------------------

northeast <- c("CT", "ME", "MA", "NH", "RI", "VT", "NJ", "NY", "PA")
midwest <- c("IL", "IN", "MI", "OH", "WI", "IA", "KS", "MN", "MO", "NE", "ND", "SD")
south <- c("DE", "FL", "GA", "MD", "NC", "SC", "VA", "WV", "DC", "AL", "KY", "MS", "TN", "AR", "LA", "OK", "TX")
west <- c("AZ", "CO", "ID", "MT", "NV", "NM", "UT", "WY", "AK", "CA", "HI", "OR", "WA")

data_final$region <- case_when(
  data_final$statecode %in% northeast ~ "Northeast",
  data_final$statecode %in% midwest ~ "Midwest",
  data_final$statecode %in% south ~ "South",
  data_final$statecode %in% west ~ "West",
  TRUE ~ "Unknown"
)

data_final$region <- factor(data_final$region, levels = c("South", "Northeast", "Midwest", "West"))

#-------------------------------------------
# RUN REGIONAL MODELS WITH CLEANED DATA
#-------------------------------------------

cat("\n=== RUNNING REGIONAL MODELS WITH COOK'S D CLEANED DATA ===\n")

regional_all_results <- list()
all_cleaned_outcomes <- c(cleaned_injury_outcomes, cleaned_incident_outcomes)

for(outcome in all_cleaned_outcomes) {
  if(outcome %in% names(data_final)) {
    original_name <- gsub("cleaned_", "", outcome)
    cat("\nAnalyzing:", original_name, "with regional effects\n")
    
    avg_n <- calculate_avg_n(data_final, outcome)
    cat("  Average N across imputations:", avg_n, "\n")
    
    # Use special predictors for firearms injuries
    if(original_name == "total_inj_firearms") {
      cat("  Using binary college variable for firearms injuries model\n")
      result <- pooled_nb_regression_enhanced(data_final, outcome, c(preds_firearms_injuries, "region"))
    } else {
      result <- pooled_nb_regression_enhanced(data_final, outcome, c(preds_full, "region"))
    }
    
    if(!is.null(result)) {
      regional_all_results[[original_name]] <- result
      regional_all_results[[original_name]]$avg_n <- avg_n
      cat("  ✓ Completed. McFadden R²:", sprintf("%.3f", result$pseudo_r2$mcfadden), "\n")
    } else {
      cat("  ✗ Model failed\n")
    }
  }
}

#-------------------------------------------
# CREATE APA TABLES WITH AVERAGE N
#-------------------------------------------

create_apa_table_with_avg_n <- function(results_list, outcome_type = "incident") {
  
  if(outcome_type == "incident") {
    outcomes <- c("total_hands", "total_knife", "total_firearms", "total_other", "total_incidents")
    col_names <- c("Hands", "Knife", "Firearms", "Other", "Total")
  } else {
    outcomes <- c("total_inj_hands", "total_inj_knife", "total_inj_firearms", 
                  "total_inj_other", "total_injuries")
    col_names <- c("Hands", "Knife", "Firearms", "Other", "Total")
  }
  
  apa_table <- data.frame(Predictor = character(), stringsAsFactors = FALSE)
  
  for(i in 1:length(outcomes)) {
    apa_table[[col_names[i]]] <- character()
  }
  
  predictor_mapping <- list(
    "ACADEMY STRUCTURE" = NULL,
    "Basic Training Length" = "z_basic_lgth_hours",
    "Field Training: Mandatory for Some" = "field_man1",
    "Field Training: Mandatory for All" = "field_man2",
    "Environment: Low Stress" = "environment_31",
    "Environment: High Stress" = "environment_33",
    "Equipment Budget" = "z_ebudget",
    "Operational Budget" = "z_opbudget",
    "Overseeing Agency: College" = c("agency_type32", "agency_college"),  # Both possible names
    "Overseeing Agency: Other" = "agency_type33",
    "Fitness Center" = "fitness_1",
    "Obstacle Courses" = "obstacle_1",
    "Firing Range" = "firerange",
    "Scenario Training" = "scenario_1",
    "Refresher Training" = "refresher",
    " " = NULL,
    "ACADEMY CURRICULUM" = NULL,
    "Force-Based Instruction" = "force_based",
    "Contemporary Policing Studies" = "contemporary_policing_composite",
    "Special Topics Study" = "special_study",
    "Full-time Sworn Instructors" = "z_ft_sworn",
    "Full-time Civilian Instructors" = "z_ft_civ",
    "Min. Education (College+)" = "min_ed_bin",
    "  " = NULL,
    "ACADEMY PERFORMANCE" = NULL,
    "Total Failed: Physical" = "z_fail_phys_total",
    "Total Failed: Academic" = "z_fail_academic_total",
    # REMOVED: "Total Failed: All Reasons" = "z_fail_total",
    "   " = NULL,
    "CONTROLS" = NULL,
    "Average Officers" = "z_mean_officers",
    "Total Violent Crime" = "z_total_violent",
    "Violent Crime Clearance Rate" = "violentclearance_rate",
    "    " = NULL,
    "REGIONAL EFFECTS" = NULL,
    "Northeast" = "regionNortheast",
    "Midwest" = "regionMidwest",
    "West" = "regionWest"
  )
  
  row_num <- 1
  for(pred_label in names(predictor_mapping)) {
    apa_table[row_num, "Predictor"] <- pred_label
    
    pred_names <- predictor_mapping[[pred_label]]
    
    if(!is.null(pred_names)) {
      for(i in 1:length(outcomes)) {
        outcome <- outcomes[i]
        col_name <- col_names[i]
        
        if(outcome %in% names(results_list) && !is.null(results_list[[outcome]])) {
          summary_df <- results_list[[outcome]]$summary
          
          # Try to find the predictor (handling both possible names for college)
          pred_row <- NULL
          for(pred_name in pred_names) {
            temp_row <- summary_df[summary_df$term == pred_name, ]
            if(nrow(temp_row) > 0) {
              pred_row <- temp_row
              break
            }
          }
          
          if(!is.null(pred_row) && nrow(pred_row) > 0) {
            irr <- pred_row$IRR[1]
            se <- pred_row$std.error[1]
            stars <- pred_row$stars[1]
            cell_value <- sprintf("%.3f%s (%.3f)", irr, stars, se)
            apa_table[row_num, col_name] <- cell_value
          } else {
            # For "Other" agency category in firearms injuries, show "-"
            if(pred_label == "Overseeing Agency: Other" && outcome == "total_inj_firearms") {
              apa_table[row_num, col_name] <- "-"
            } else {
              apa_table[row_num, col_name] <- "-"
            }
          }
        } else {
          apa_table[row_num, col_name] <- "-"
        }
      }
    } else {
      for(col_name in col_names) {
        apa_table[row_num, col_name] <- ""
      }
    }
    
    row_num <- row_num + 1
  }
  
  # Add model fit statistics
  apa_table[nrow(apa_table) + 1, "Predictor"] <- ""
  for(col_name in col_names) {
    apa_table[nrow(apa_table), col_name] <- ""
  }
  
  apa_table[nrow(apa_table) + 1, "Predictor"] <- "MODEL FIT"
  for(col_name in col_names) {
    apa_table[nrow(apa_table), col_name] <- ""
  }
  
  # McFadden R²
  apa_table[nrow(apa_table) + 1, "Predictor"] <- "McFadden R²"
  for(i in 1:length(outcomes)) {
    outcome <- outcomes[i]
    col_name <- col_names[i]
    
    if(outcome %in% names(results_list) && !is.null(results_list[[outcome]])) {
      r2 <- results_list[[outcome]]$pseudo_r2$mcfadden
      apa_table[nrow(apa_table), col_name] <- sprintf("%.3f", r2)
    } else {
      apa_table[nrow(apa_table), col_name] <- "-"
    }
  }
  
  # Nagelkerke R²
  apa_table[nrow(apa_table) + 1, "Predictor"] <- "Nagelkerke R²"
  for(i in 1:length(outcomes)) {
    outcome <- outcomes[i]
    col_name <- col_names[i]
    
    if(outcome %in% names(results_list) && !is.null(results_list[[outcome]])) {
      r2 <- results_list[[outcome]]$pseudo_r2$nagelkerke
      apa_table[nrow(apa_table), col_name] <- sprintf("%.3f", r2)
    } else {
      apa_table[nrow(apa_table), col_name] <- "-"
    }
  }
  
  # AIC
  apa_table[nrow(apa_table) + 1, "Predictor"] <- "AIC"
  for(i in 1:length(outcomes)) {
    outcome <- outcomes[i]
    col_name <- col_names[i]
    
    if(outcome %in% names(results_list) && !is.null(results_list[[outcome]])) {
      aic <- results_list[[outcome]]$avg_aic
      apa_table[nrow(apa_table), col_name] <- sprintf("%.1f", aic)
    } else {
      apa_table[nrow(apa_table), col_name] <- "-"
    }
  }
  
  # Average N
  apa_table[nrow(apa_table) + 1, "Predictor"] <- "N (average)"
  for(i in 1:length(outcomes)) {
    outcome <- outcomes[i]
    col_name <- col_names[i]
    
    if(outcome %in% names(results_list) && !is.null(results_list[[outcome]])) {
      if(!is.null(results_list[[outcome]]$avg_n)) {
        n <- results_list[[outcome]]$avg_n
      } else {
        n <- results_list[[outcome]]$n_obs
      }
      apa_table[nrow(apa_table), col_name] <- sprintf("%d", n)
    } else {
      apa_table[nrow(apa_table), col_name] <- "-"
    }
  }
  
  return(apa_table)
}

#-------------------------------------------
# GENERATE AND EXPORT TABLES
#-------------------------------------------

cat("\n=== CREATING FINAL TABLES ===\n")

injury_table <- create_apa_table_with_avg_n(regional_all_results, outcome_type = "injury")
incident_table <- create_apa_table_with_avg_n(regional_all_results, outcome_type = "incident")

# Print tables
cat("\n=====================================\n")
cat("TABLE 1: OFFICER INJURIES (WITH COOK'S D)\n")
cat("=====================================\n\n")
print(injury_table, row.names = FALSE, right = FALSE)

cat("\n=====================================\n")
cat("TABLE 2: OFFICER INCIDENTS (WITH COOK'S D)\n")
cat("=====================================\n\n")
print(incident_table, row.names = FALSE, right = FALSE)

# Save to both locations
write.csv(injury_table, paste0(save_path, "table_officer_injuries_cooksd_apa.csv"), row.names = FALSE)
write.csv(incident_table, paste0(save_path, "table_officer_incidents_cooksd_apa.csv"), row.names = FALSE)
write.csv(injury_table, paste0(downloads_path, "table_officer_injuries_cooksd_apa.csv"), row.names = FALSE)
write.csv(incident_table, paste0(downloads_path, "table_officer_incidents_cooksd_apa.csv"), row.names = FALSE)

# Create Excel workbook
wb <- createWorkbook()
addWorksheet(wb, "Officer Injuries")
writeData(wb, sheet = "Officer Injuries", injury_table, rowNames = FALSE)
addWorksheet(wb, "Officer Incidents")
writeData(wb, sheet = "Officer Incidents", incident_table, rowNames = FALSE)
saveWorkbook(wb, paste0(downloads_path, "nb_results_cooksd_tables.xlsx"), overwrite = TRUE)

#-------------------------------------------
# SUMMARY OF SAMPLE SIZES
#-------------------------------------------

cat("\n\n", strrep("=", 80), "\n")
cat("SUMMARY: SAMPLE SIZE CHANGES DUE TO COOK'S D\n")
cat(strrep("=", 80), "\n\n")

cat("Original N per imputation: 324\n")
cat("After removing clearance rate outliers: 322\n\n")

cat("Average N after Cook's D removal:\n")
cat(strrep("-", 40), "\n")

cat("\nINJURY OUTCOMES:\n")
for(outcome in names(regional_all_results)) {
  if(grepl("inj", outcome)) {
    avg_n <- regional_all_results[[outcome]]$avg_n
    removed <- 322 - avg_n
    pct_removed <- round((removed/322) * 100, 1)
    cat(sprintf("  %-25s: %3d (removed %2d, %.1f%%)\n", 
                outcome, avg_n, removed, pct_removed))
  }
}

cat("\nINCIDENT OUTCOMES:\n")
for(outcome in names(regional_all_results)) {
  if(!grepl("inj", outcome)) {
    avg_n <- regional_all_results[[outcome]]$avg_n
    removed <- 322 - avg_n
    pct_removed <- round((removed/322) * 100, 1)
    cat(sprintf("  %-25s: %3d (removed %2d, %.1f%%)\n", 
                outcome, avg_n, removed, pct_removed))
  }
}

cat("\n✓ ANALYSIS COMPLETE\n")
cat("✓ Cook's D applied to ALL outcomes (injuries and incidents)\n")
cat("✓ VIF check performed before models\n")
cat("✓ Binary college variable used for firearms injuries model\n")
cat("✓ Total Failed: All Reasons variable removed\n")
cat("✓ Tables report average N across 20 imputations\n")
cat("✓ Files saved with '_cooksd' suffix\n")
